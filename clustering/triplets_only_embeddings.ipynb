{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Genome Region Description Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 13:59:45.374521: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from visual_genome import api as vg\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from nltk.cluster import KMeansClusterer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from nltk.cluster import KMeansClusterer\n",
    "from scipy.spatial import distance_matrix, distance\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_path = '/home/maelic/Documents/PhD/Datasets/VisualGenome/original_annotations/region_descriptions.json'\n",
    "vg_img_path = '/home/maelic/Documents/PhD/Datasets/VisualGenome/VG_100K'\n",
    "rel_path = '/home/maelic/Documents/PhD/Datasets/VisualGenome/original_annotations/relationships.json'\n",
    "h5_path = '/home/maelic/Documents/PhD/MyModel/PhD_Commonsense_Enrichment/VG_refinement/data_tools/VG80K/VG80K-SGG.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read relationships from disk using rel path\n",
    "relations_file = json.load(open(rel_path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-trained models\n",
    "model_name='all-mpnet-base-v2'\n",
    "\n",
    "# Possible value:\n",
    "# 'all-mpnet-base-v2' : Best accuracy overall\n",
    "# 'all-MiniLM-L12-v2' : Faster\n",
    "# 'all-roberta-large-v1' : Better but slower\n",
    "\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read images and their descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read images triplets\n",
    "relationships = []\n",
    "for idx, img in enumerate(relations_file):\n",
    "    rel_img = []\n",
    "    for rel in img['relationships']:\n",
    "        pred = rel['predicate']\n",
    "        if 'names' in rel['object'].keys():\n",
    "            obj = rel['object']['names'][0]\n",
    "        else:\n",
    "            obj = rel['object']['name']\n",
    "        if 'names' in rel['subject'].keys():\n",
    "            sub = rel['subject']['names'][0]\n",
    "        else:\n",
    "            sub = rel['subject']['name']\n",
    "        \n",
    "        rel_img.append(str(sub) + ' ' + str(pred.lower()) + ' ' + str(obj))\n",
    "    if len(rel_img) > 0:\n",
    "        relationships.append({'Image_id': idx, 'Triplets': rel_img})\n",
    "relationships = pd.DataFrame(relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for idx, rel in enumerate(relationships[\"Triplets\"].tolist()):\n",
    "    if rel == []:\n",
    "        sum += 1\n",
    "        print(relationships['Image_id'][idx])\n",
    "print(sum)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_emb_path = \"/home/maelic/Documents/PhD/MyModel/PhD_Commonsense_Enrichment/VG_refinement/clustering/sentence_embeddings/\"+model_name+\"_triplets_embeddings.pkl\"\n",
    "\n",
    "if not os.path.exists(region_emb_path):\n",
    "    values = []\n",
    "    for corpus in tqdm(relationships[\"Triplets\"].tolist()):\n",
    "        # Number of rows corresponds to number of sentences\n",
    "        if corpus:\n",
    "            emb = model.encode(corpus)\n",
    "            # get mean value columnwise, so that sentence embeddings are averaged per region for each image\n",
    "            emb = np.mean(np.array(emb), axis=0) \n",
    "            # for each model, a 768-length embedding is stored\n",
    "            values.append(emb)\n",
    "        # 3225 images have no relationships\n",
    "        else:\n",
    "            values.append(0)\n",
    "\n",
    "    relationships['embeddings'] = pd.Series(values, index=relationships.index) \n",
    "    # number of sentences x 768\n",
    "    relationships.head()\n",
    "\n",
    "    with open(region_emb_path, \"wb\") as fOut:\n",
    "        pickle.dump(relationships,fOut,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    with open(region_emb_path, \"rb\") as fIn:\n",
    "        relationships = pickle.load(fIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Image_id', 'Triplets', 'embeddings'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(relationships.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_question(triplets_embeddings, NUM_CLUSTERS):\n",
    "\n",
    "    sentences = triplets_embeddings['Triplets']\n",
    "\n",
    "    X = np.array(triplets_embeddings['embeddings'].tolist(), dtype=object)\n",
    "\n",
    "    data = triplets_embeddings[['Image_id', 'Triplets', 'embeddings']].copy()\n",
    "    \n",
    "    kclusterer = KMeansClusterer(\n",
    "        NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance,\n",
    "        avoid_empty_clusters=True)\n",
    "\n",
    "    assigned_clusters = kclusterer.cluster(data['embeddings'], assign_clusters=True)\n",
    "\n",
    "    data['cluster'] = pd.Series(assigned_clusters, index=data.index)\n",
    "    data['centroid'] = data['cluster'].apply(lambda x: kclusterer.means()[x])\n",
    "\n",
    "    return data, assigned_clusters\n",
    "\n",
    "def distance_from_centroid(row):\n",
    "    # type of emb and centroid is different, hence using tolist below\n",
    "    return distance_matrix([row['embeddings']], [row['centroid'].tolist()])[0][0]\n",
    "    \n",
    "def make_clusters(triplets_embeddings, n_clusters):\n",
    "    data, assigned_clusters = clustering_question(triplets_embeddings, NUM_CLUSTERS = n_clusters)\n",
    "    # Compute centroid distance to the data\n",
    "    data['distance_from_centroid'] = data.apply(distance_from_centroid, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 3/19 [00:43<04:15, 15.97s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "def nltk_inertia(feature_matrix, centroid):\n",
    "    sum_ = []\n",
    "    for i in range(feature_matrix.shape[0]):\n",
    "        sum_.append(np.sum((feature_matrix[i] - centroid[i])**2))  \n",
    "\n",
    "    return sum(sum_) \n",
    "def number_of_clusters(image_regions, max_clusters=20):\n",
    "    sse = []\n",
    "    list_k = list(range(2, max_clusters+1))\n",
    "\n",
    "    for k in tqdm(list_k):\n",
    "        data, assigned_clusters = clustering_question(image_regions, k)\n",
    "        sse.append(nltk_inertia(data['embeddings'].to_numpy(), data.centroid.to_numpy()))\n",
    "\n",
    "    # Plot sse against k\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.title('Elbow method for '+model_name)\n",
    "    plt.plot(list_k, sse, '-o')\n",
    "    plt.xlabel('Number of clusters k')\n",
    "    plt.ylabel('Sum of squared distance')\n",
    "    plt.show()\n",
    "\n",
    "number_of_clusters(relationships, max_clusters=20)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_visual(embedding_clusters, n_clusters=0, save=False):\n",
    "    mat = np.matrix([x for x in embedding_clusters['embeddings']])\n",
    "    t_sne = TSNE(n_components=2)\n",
    "    low_dim_data = t_sne.fit_transform(np.asarray(mat))\n",
    "    print('Lower dim data has shape',low_dim_data.shape)\n",
    "    tsne_df =  pd.DataFrame(low_dim_data, embedding_clusters['cluster'])\n",
    "    plt.figure(figsize=(20,12))\n",
    "    ax = sns.scatterplot(data=tsne_df[0], x=tsne_df[0], y=tsne_df[1], hue=tsne_df.index, palette = \"viridis\", s=80)\n",
    "    ax.set_title('T-SNE '+model_name+' Embeddings')\n",
    "    plt.draw()\n",
    "    if save:\n",
    "        plt.savefig(\"visualization/triplets/\"+model_name+\"_tsne_clusters_\"+str(n_clusters)+\".png\")\n",
    "    return low_dim_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar image retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.OutputArea.auto_scroll_threshold = 9999;\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distances(images_regions, input_id, input_embedding = np.zeros(5)):\n",
    "    distances = []     \n",
    "    image_ids=images_regions.Image_id\n",
    "    if input_id>0:\n",
    "        reference_embedding = images_regions.loc[images_regions.Image_id == input_id]['embeddings']\n",
    "        reference_embedding = reference_embedding.values[0].reshape(-1,1)\n",
    "        corpus_embeddings = images_regions.loc[images_regions.Image_id != input_id]['embeddings']\n",
    "    else:\n",
    "        reference_embedding = input_embedding\n",
    "        corpus_embeddings = images_regions['embeddings']\n",
    "        \n",
    "    for j in range(len(corpus_embeddings)):  # rows of def_embeddings matrix\n",
    "        defin = j\n",
    "        if image_ids[j]!=input_id:      # avoid calculating distance with itself\n",
    "            corpus = corpus_embeddings[j].reshape(-1,1)\n",
    "            # euclidean distance between multidimensional vectors\n",
    "            #dist = distance.euclidean(np.asarray(reference_embedding)[0], np.asarray(corpus)[0])\n",
    "            dist = distance.euclidean(reference_embedding.flatten(), corpus.flatten())\n",
    "\n",
    "            distances.append([image_ids[j], dist]) \n",
    "        \n",
    "    # store in df\n",
    "    col_names = ['image_id', 'distances']\n",
    "    distances_df = pd.DataFrame(distances, columns=col_names)\n",
    "    distances_df = distances_df.sort_values(by='distances', ascending=True)\n",
    "    distances_df.to_csv('distances.csv', index=False)\n",
    "    return distances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given image id to retrieve its k most similar images\n",
    "\n",
    "def retrieve_images(key, images_regions, input_id = -1, input_embedding = np.zeros(5)):\n",
    "    top_k=10\n",
    "    \n",
    "    if input_id>0:\n",
    "    # top_k results to return\n",
    "        print('Reference image:', input_id)\n",
    "        retrieve_image(input_id)\n",
    "        distances_df=find_distances(images_regions, input_id)\n",
    "    else:\n",
    "        distances_df=find_distances(images_regions, input_id, input_embedding)\n",
    "    top_images=distances_df.head(top_k)\n",
    "\n",
    "    print(\"Top\", top_k, \"most similar images to image\", input_id, \"in Visual Genome:\")\n",
    "    for index, row in top_images.iterrows():   \n",
    "        im_id = int(row.image_id)\n",
    "        print(\"Image id:\", im_id, \"Euclidean distance: %.4f\" % (row.distances))\n",
    "\n",
    "        # find similar images from api and show\n",
    "        retrieve_image(im_id)\n",
    "\n",
    "    return top_images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method: stsb-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 4\n",
      "         Image_id  Triplets  embeddings  centroid  distance_from_centroid\n",
      "cluster                                                                  \n",
      "0           27513     27513       27513     27513                   27513\n",
      "1           16752     16752       16752     16752                   16752\n",
      "2           29979     29979       29979     29979                   29979\n",
      "3           30608     30608       30608     30608                   30608\n",
      "Lower dim data has shape (104852, 2)\n",
      "For n_clusters = 4 The average silhouette_score is : 0.24654890596866608\n",
      "Number of clusters: 5\n",
      "         Image_id  Triplets  embeddings  centroid  distance_from_centroid\n",
      "cluster                                                                  \n",
      "0           26716     26716       26716     26716                   26716\n",
      "1           12138     12138       12138     12138                   12138\n",
      "2           26735     26735       26735     26735                   26735\n",
      "3           23212     23212       23212     23212                   23212\n",
      "4           16051     16051       16051     16051                   16051\n",
      "Lower dim data has shape (104852, 2)\n",
      "For n_clusters = 5 The average silhouette_score is : 0.19847990572452545\n",
      "Number of clusters: 6\n",
      "         Image_id  Triplets  embeddings  centroid  distance_from_centroid\n",
      "cluster                                                                  \n",
      "0           21438     21438       21438     21438                   21438\n",
      "1           15816     15816       15816     15816                   15816\n",
      "2           25104     25104       25104     25104                   25104\n",
      "3            8320      8320        8320      8320                    8320\n",
      "4           22818     22818       22818     22818                   22818\n",
      "5           11356     11356       11356     11356                   11356\n",
      "Lower dim data has shape (104852, 2)\n",
      "For n_clusters = 6 The average silhouette_score is : 0.12287836521863937\n",
      "Number of clusters: 7\n",
      "         Image_id  Triplets  embeddings  centroid  distance_from_centroid\n",
      "cluster                                                                  \n",
      "0           11174     11174       11174     11174                   11174\n",
      "1           16519     16519       16519     16519                   16519\n",
      "2           10144     10144       10144     10144                   10144\n",
      "3            8111      8111        8111      8111                    8111\n",
      "4           22266     22266       22266     22266                   22266\n",
      "5           15362     15362       15362     15362                   15362\n",
      "6           21276     21276       21276     21276                   21276\n",
      "Lower dim data has shape (104852, 2)\n",
      "For n_clusters = 7 The average silhouette_score is : 0.14903785288333893\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "clusters_max = 21\n",
    "\n",
    "score_list = {}\n",
    "\n",
    "for i in range(2, clusters_max):\n",
    "    embedding_clusters=make_clusters(relationships, i)\n",
    "    print('Number of clusters:', i)\n",
    "    print(embedding_clusters.groupby('cluster').count())\n",
    "    low_embedding_clusters = tsne_visual(embedding_clusters, n_clusters=i, save=True)\n",
    "\n",
    "    # Get silhouette samples\n",
    "    low_embedding_clusters = low_embedding_clusters\n",
    "    embedding_clusters = embedding_clusters\n",
    "\n",
    "    plt.figure(figsize=(20,12))\n",
    "\n",
    "    embedding_samples = low_embedding_clusters\n",
    "    labels = embedding_clusters['cluster'].to_numpy()\n",
    "    silhouette_vals = silhouette_samples(embedding_samples, labels)\n",
    "    avg_score = silhouette_score(embedding_samples, labels)\n",
    "    print(f\"For n_clusters = {i} The average silhouette_score is : {avg_score}\")\n",
    "    score_list[i] = {'score': avg_score, 'silhouette_vals': silhouette_vals}\n",
    "\n",
    "    # Silhouette plot\n",
    "    y_ticks = []\n",
    "    y_lower, y_upper = 0, 0\n",
    "    for i, cluster in enumerate(np.unique(labels)):\n",
    "        cluster_silhouette_vals = silhouette_vals[labels == cluster]\n",
    "        cluster_silhouette_vals.sort()\n",
    "        y_upper += len(cluster_silhouette_vals)\n",
    "        plt.barh(range(y_lower, y_upper), cluster_silhouette_vals, edgecolor='none', height=1)\n",
    "        plt.text(-0.03, (y_lower + y_upper) / 2, str(i + 1))\n",
    "        y_lower += len(cluster_silhouette_vals)\n",
    "\n",
    "    avg_score = np.mean(silhouette_vals)\n",
    "    plt.axvline(avg_score, linestyle='--', linewidth=2, color='green')\n",
    "    plt.yticks([])\n",
    "    plt.xlim([-0.1, 1])\n",
    "    plt.xlabel('Silhouette coefficient values')\n",
    "    plt.ylabel('Cluster labels')\n",
    "    plt.title(f'Silhouette analysis using k = {i}, average score = {avg_score:.3f}', y=1.02)\n",
    "    # title=f'Silhouette analysis using k = {i}, average score = {avg_score:.3f}'\n",
    "    # plt.suptitle(title, fontsize=16, y=1.05)\n",
    "    plt.draw()\n",
    "    plt.savefig(\"visualization/triplets/\"+model_name+\"_silhouette_clusters_embeddings_\"+str(i)+\".png\")\n",
    "\n",
    "# write to log file:\n",
    "with open('visualization/triplets/'+model_name+'_clusters_score_log_.txt', 'w') as f:\n",
    "    for key, value in score_list.items():\n",
    "        f.write('%s: %s \\n' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_method = \"embeddings\"\n",
    "num_clusters = 9\n",
    "\n",
    "embedding_clusters=make_clusters(relationships, num_clusters)\n",
    "print('Number of clusters:', num_clusters)\n",
    "print(embedding_clusters.groupby('cluster').count())\n",
    "low_embedding_clusters = tsne_visual(embedding_clusters, n_clusters=num_clusters, save=True)\n",
    "\n",
    "# Get silhouette samples\n",
    "low_embedding_clusters = low_embedding_clusters\n",
    "embedding_clusters = embedding_clusters\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "\n",
    "embedding_samples = low_embedding_clusters\n",
    "labels = embedding_clusters['cluster'].to_numpy()\n",
    "silhouette_vals = silhouette_samples(embedding_samples, labels)\n",
    "avg_score = silhouette_score(embedding_samples, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding_clusters.keys())\n",
    "i=0\n",
    "for idx, img in embedding_clusters.iterrows():\n",
    "    if img['cluster'] == 8:\n",
    "        print(img['Image_id'])\n",
    "        print(img['region_sentences'])\n",
    "        i+=1\n",
    "        if i>10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding_clusters.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar image retrieval based on given image id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id = 1\n",
    "top_images = retrieve_images(embeddings_method, image_regions, input_id = input_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar image retrieval based on given user sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'a cat is sleeping on the beach'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embedding = get_embeddings(model_4, input_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_images_2 = retrieve_images(embeddings_method, image_regions, input_id = -1, input_embedding=input_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_images_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7938123ceb831a528202b02dbdb8fd920084013224d6ffd4fcb9a5f6f5074515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
